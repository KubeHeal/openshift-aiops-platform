{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Healing Workflows (Enhanced)\n",
    "\n",
    "## Overview\n",
    "This notebook implements hybrid healing workflows that combine rule-based and AI-driven remediation approaches. It intelligently routes decisions between deterministic rules and ML models, optimizing for both reliability and adaptability.\n",
    "\n",
    "## Enhancements in This Version\n",
    "- **Rule Engine**: Proper rule-based remediation with configurable rules\n",
    "- **Intelligent Routing**: Routes based on anomaly type, confidence, and historical performance\n",
    "- **Adaptive Learning**: Adjusts routing weights based on outcome feedback\n",
    "- **Integrated Feedback**: Connects to outcome tracking for continuous improvement\n",
    "\n",
    "## Prerequisites\n",
    "- Completed: `ai-driven-decision-making-enhanced.ipynb`\n",
    "- Prometheus accessible (or simulated)\n",
    "- Feedback data available\n",
    "\n",
    "## Learning Objectives\n",
    "- Combine rule-based and AI-driven approaches effectively\n",
    "- Route decisions based on context and historical performance\n",
    "- Implement proper fallback chains with escalation\n",
    "- Track and compare approach effectiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import pickle\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Tuple, Any, Callable\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from enum import Enum\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Setup path for utils module\n",
    "def find_utils_path():\n",
    "    \"\"\"Find utils path regardless of current working directory\"\"\"\n",
    "    possible_paths = [\n",
    "        Path(__file__).parent.parent / 'utils' if '__file__' in dir() else None,\n",
    "        Path.cwd() / 'notebooks' / 'utils',\n",
    "        Path.cwd().parent / 'utils',\n",
    "        Path('/workspace/repo/notebooks/utils'),\n",
    "        Path('/opt/app-root/src/notebooks/utils'),\n",
    "    ]\n",
    "    for p in possible_paths:\n",
    "        if p and p.exists() and (p / 'common_functions.py').exists():\n",
    "            return str(p)\n",
    "    return None\n",
    "\n",
    "utils_path = find_utils_path()\n",
    "if utils_path:\n",
    "    sys.path.insert(0, utils_path)\n",
    "    print(f\"✅ Utils path found: {utils_path}\")\n",
    "\n",
    "# Try to import common functions, with fallback\n",
    "try:\n",
    "    from common_functions import setup_environment\n",
    "    print(\"✅ Common functions imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"⚠️ Using fallback setup_environment\")\n",
    "    def setup_environment():\n",
    "        os.makedirs('/opt/app-root/src/data/processed', exist_ok=True)\n",
    "        os.makedirs('/opt/app-root/src/models', exist_ok=True)\n",
    "        return {'data_dir': '/opt/app-root/src/data', 'models_dir': '/opt/app-root/src/models'}\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Setup environment\n",
    "env_info = setup_environment()\n",
    "logger.info(f\"Environment ready: {env_info}\")\n",
    "\n",
    "# Define paths\n",
    "MODELS_DIR = Path('/opt/app-root/src/models')\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DATA_DIR = Path('/opt/app-root/src/data')\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FEEDBACK_DIR = DATA_DIR / 'feedback'\n",
    "FEEDBACK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Configuration\n",
    "NAMESPACE = 'self-healing-platform'\n",
    "AI_CONFIDENCE_THRESHOLD = 0.75\n",
    "HIGH_CONFIDENCE_THRESHOLD = 0.90\n",
    "PROMETHEUS_URL = os.getenv('PROMETHEUS_URL', 'http://prometheus:9090')\n",
    "\n",
    "logger.info(f\"Hybrid healing workflows initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Rule-Based Remediation Engine\n",
    "\n",
    "Define deterministic rules for known anomaly patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Severity(Enum):\n",
    "    \"\"\"Anomaly severity levels.\"\"\"\n",
    "    LOW = 'low'\n",
    "    MEDIUM = 'medium'\n",
    "    HIGH = 'high'\n",
    "    CRITICAL = 'critical'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Rule:\n",
    "    \"\"\"A remediation rule definition.\"\"\"\n",
    "    rule_id: str\n",
    "    name: str\n",
    "    description: str\n",
    "    condition: Callable[[Dict], bool]\n",
    "    action: str\n",
    "    severity_threshold: Severity\n",
    "    cooldown_seconds: int = 300\n",
    "    max_executions_per_hour: int = 5\n",
    "    requires_approval: bool = False\n",
    "    enabled: bool = True\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RuleMatch:\n",
    "    \"\"\"Result of a rule evaluation.\"\"\"\n",
    "    rule_id: str\n",
    "    rule_name: str\n",
    "    matched: bool\n",
    "    action: str\n",
    "    confidence: float  # Rule-based confidence (1.0 for exact match)\n",
    "    severity: Severity\n",
    "    reasoning: str\n",
    "    metadata: Dict = field(default_factory=dict)\n",
    "\n",
    "\n",
    "class RuleEngine:\n",
    "    \"\"\"\n",
    "    Rule-based remediation engine.\n",
    "    \n",
    "    Evaluates deterministic rules against metrics and anomaly data\n",
    "    to produce remediation decisions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rules: List[Rule] = []\n",
    "        self._execution_history: Dict[str, List[datetime]] = defaultdict(list)\n",
    "        self._last_execution: Dict[str, datetime] = {}\n",
    "        self._register_default_rules()\n",
    "    \n",
    "    def _register_default_rules(self):\n",
    "        \"\"\"Register default remediation rules.\"\"\"\n",
    "        \n",
    "        # Rule 1: High CPU\n",
    "        self.register_rule(Rule(\n",
    "            rule_id='rule_high_cpu',\n",
    "            name='High CPU Usage',\n",
    "            description='Remediate when CPU usage exceeds 85%',\n",
    "            condition=lambda m: m.get('cpu_usage', 0) > 85,\n",
    "            action='scale_horizontal',\n",
    "            severity_threshold=Severity.HIGH,\n",
    "            cooldown_seconds=300,\n",
    "            max_executions_per_hour=3\n",
    "        ))\n",
    "        \n",
    "        # Rule 2: Critical CPU\n",
    "        self.register_rule(Rule(\n",
    "            rule_id='rule_critical_cpu',\n",
    "            name='Critical CPU Usage',\n",
    "            description='Emergency action when CPU exceeds 95%',\n",
    "            condition=lambda m: m.get('cpu_usage', 0) > 95,\n",
    "            action='emergency_scale',\n",
    "            severity_threshold=Severity.CRITICAL,\n",
    "            cooldown_seconds=60,\n",
    "            max_executions_per_hour=10\n",
    "        ))\n",
    "        \n",
    "        # Rule 3: High Memory\n",
    "        self.register_rule(Rule(\n",
    "            rule_id='rule_high_memory',\n",
    "            name='High Memory Usage',\n",
    "            description='Remediate when memory usage exceeds 90%',\n",
    "            condition=lambda m: m.get('memory_percent', 0) > 90,\n",
    "            action='restart_pod',\n",
    "            severity_threshold=Severity.HIGH,\n",
    "            cooldown_seconds=600,\n",
    "            max_executions_per_hour=2\n",
    "        ))\n",
    "        \n",
    "        # Rule 4: OOM Risk\n",
    "        self.register_rule(Rule(\n",
    "            rule_id='rule_oom_risk',\n",
    "            name='OOM Risk Detection',\n",
    "            description='Prevent OOM by acting when memory exceeds 95%',\n",
    "            condition=lambda m: m.get('memory_percent', 0) > 95,\n",
    "            action='increase_memory_limit',\n",
    "            severity_threshold=Severity.CRITICAL,\n",
    "            cooldown_seconds=120,\n",
    "            max_executions_per_hour=5\n",
    "        ))\n",
    "        \n",
    "        # Rule 5: High Error Rate\n",
    "        self.register_rule(Rule(\n",
    "            rule_id='rule_high_error_rate',\n",
    "            name='High Error Rate',\n",
    "            description='Remediate when error ratio exceeds 10%',\n",
    "            condition=lambda m: m.get('error_ratio', 0) > 0.10,\n",
    "            action='restart_pod',\n",
    "            severity_threshold=Severity.HIGH,\n",
    "            cooldown_seconds=300,\n",
    "            max_executions_per_hour=4\n",
    "        ))\n",
    "        \n",
    "        # Rule 6: Critical Error Rate\n",
    "        self.register_rule(Rule(\n",
    "            rule_id='rule_critical_error_rate',\n",
    "            name='Critical Error Rate',\n",
    "            description='Rollback when error ratio exceeds 25%',\n",
    "            condition=lambda m: m.get('error_ratio', 0) > 0.25,\n",
    "            action='rollback_deployment',\n",
    "            severity_threshold=Severity.CRITICAL,\n",
    "            cooldown_seconds=600,\n",
    "            max_executions_per_hour=2,\n",
    "            requires_approval=True\n",
    "        ))\n",
    "        \n",
    "        # Rule 7: High Latency\n",
    "        self.register_rule(Rule(\n",
    "            rule_id='rule_high_latency',\n",
    "            name='High Latency',\n",
    "            description='Scale when P99 latency exceeds 1000ms',\n",
    "            condition=lambda m: m.get('latency_p99', 0) > 1000,\n",
    "            action='scale_horizontal',\n",
    "            severity_threshold=Severity.MEDIUM,\n",
    "            cooldown_seconds=300,\n",
    "            max_executions_per_hour=4\n",
    "        ))\n",
    "        \n",
    "        # Rule 8: Crash Loop Detection\n",
    "        self.register_rule(Rule(\n",
    "            rule_id='rule_crash_loop',\n",
    "            name='Crash Loop Detection',\n",
    "            description='Handle pods in crash loop (>3 restarts)',\n",
    "            condition=lambda m: m.get('restart_count', 0) > 3,\n",
    "            action='diagnose_and_restart',\n",
    "            severity_threshold=Severity.HIGH,\n",
    "            cooldown_seconds=900,\n",
    "            max_executions_per_hour=2\n",
    "        ))\n",
    "        \n",
    "        # Rule 9: Network Saturation\n",
    "        self.register_rule(Rule(\n",
    "            rule_id='rule_network_saturation',\n",
    "            name='Network Saturation',\n",
    "            description='Scale when network I/O is saturated',\n",
    "            condition=lambda m: (m.get('network_rx', 0) + m.get('network_tx', 0)) > 1e9,  # 1 GB/s\n",
    "            action='scale_horizontal',\n",
    "            severity_threshold=Severity.MEDIUM,\n",
    "            cooldown_seconds=600,\n",
    "            max_executions_per_hour=3\n",
    "        ))\n",
    "        \n",
    "        # Rule 10: Disk Pressure\n",
    "        self.register_rule(Rule(\n",
    "            rule_id='rule_disk_pressure',\n",
    "            name='Disk Pressure',\n",
    "            description='Clean up when disk usage exceeds 85%',\n",
    "            condition=lambda m: m.get('disk_usage', 0) > 85,\n",
    "            action='cleanup_disk',\n",
    "            severity_threshold=Severity.MEDIUM,\n",
    "            cooldown_seconds=1800,\n",
    "            max_executions_per_hour=2\n",
    "        ))\n",
    "        \n",
    "        logger.info(f\"Registered {len(self.rules)} default rules\")\n",
    "    \n",
    "    def register_rule(self, rule: Rule):\n",
    "        \"\"\"Register a new rule.\"\"\"\n",
    "        self.rules.append(rule)\n",
    "    \n",
    "    def _check_cooldown(self, rule_id: str, cooldown_seconds: int) -> bool:\n",
    "        \"\"\"Check if rule is still in cooldown period.\"\"\"\n",
    "        if rule_id not in self._last_execution:\n",
    "            return False\n",
    "        elapsed = (datetime.now() - self._last_execution[rule_id]).total_seconds()\n",
    "        return elapsed < cooldown_seconds\n",
    "    \n",
    "    def _check_rate_limit(self, rule_id: str, max_per_hour: int) -> bool:\n",
    "        \"\"\"Check if rule has exceeded rate limit.\"\"\"\n",
    "        cutoff = datetime.now() - timedelta(hours=1)\n",
    "        recent = [t for t in self._execution_history[rule_id] if t > cutoff]\n",
    "        self._execution_history[rule_id] = recent  # Cleanup old entries\n",
    "        return len(recent) >= max_per_hour\n",
    "    \n",
    "    def _record_execution(self, rule_id: str):\n",
    "        \"\"\"Record rule execution for cooldown and rate limiting.\"\"\"\n",
    "        now = datetime.now()\n",
    "        self._last_execution[rule_id] = now\n",
    "        self._execution_history[rule_id].append(now)\n",
    "    \n",
    "    def evaluate(self, metrics: Dict[str, float]) -> List[RuleMatch]:\n",
    "        \"\"\"\n",
    "        Evaluate all rules against current metrics.\n",
    "        \n",
    "        Args:\n",
    "            metrics: Current metric values\n",
    "        \n",
    "        Returns:\n",
    "            List of matched rules with actions\n",
    "        \"\"\"\n",
    "        matches = []\n",
    "        \n",
    "        for rule in self.rules:\n",
    "            if not rule.enabled:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                matched = rule.condition(metrics)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Rule {rule.rule_id} evaluation error: {e}\")\n",
    "                continue\n",
    "            \n",
    "            if matched:\n",
    "                # Check cooldown and rate limits\n",
    "                in_cooldown = self._check_cooldown(rule.rule_id, rule.cooldown_seconds)\n",
    "                rate_limited = self._check_rate_limit(rule.rule_id, rule.max_executions_per_hour)\n",
    "                \n",
    "                if in_cooldown:\n",
    "                    reasoning = f\"Rule matched but in cooldown period\"\n",
    "                    confidence = 0.0\n",
    "                elif rate_limited:\n",
    "                    reasoning = f\"Rule matched but rate limited\"\n",
    "                    confidence = 0.0\n",
    "                else:\n",
    "                    reasoning = f\"Rule condition satisfied: {rule.description}\"\n",
    "                    confidence = 1.0  # Rules have binary confidence\n",
    "                \n",
    "                matches.append(RuleMatch(\n",
    "                    rule_id=rule.rule_id,\n",
    "                    rule_name=rule.name,\n",
    "                    matched=True,\n",
    "                    action=rule.action,\n",
    "                    confidence=confidence,\n",
    "                    severity=rule.severity_threshold,\n",
    "                    reasoning=reasoning,\n",
    "                    metadata={\n",
    "                        'requires_approval': rule.requires_approval,\n",
    "                        'in_cooldown': in_cooldown,\n",
    "                        'rate_limited': rate_limited\n",
    "                    }\n",
    "                ))\n",
    "        \n",
    "        # Sort by severity (critical first)\n",
    "        severity_order = {Severity.CRITICAL: 0, Severity.HIGH: 1, Severity.MEDIUM: 2, Severity.LOW: 3}\n",
    "        matches.sort(key=lambda m: severity_order.get(m.severity, 4))\n",
    "        \n",
    "        return matches\n",
    "    \n",
    "    def get_best_action(self, metrics: Dict[str, float]) -> Optional[RuleMatch]:\n",
    "        \"\"\"\n",
    "        Get the highest priority actionable rule match.\n",
    "        \n",
    "        Returns:\n",
    "            Best matching rule or None if no rules match\n",
    "        \"\"\"\n",
    "        matches = self.evaluate(metrics)\n",
    "        actionable = [m for m in matches if m.confidence > 0]\n",
    "        return actionable[0] if actionable else None\n",
    "\n",
    "\n",
    "# Initialize rule engine\n",
    "rule_engine = RuleEngine()\n",
    "\n",
    "# Test with sample metrics\n",
    "test_metrics = {\n",
    "    'cpu_usage': 88,\n",
    "    'memory_percent': 75,\n",
    "    'error_ratio': 0.05,\n",
    "    'latency_p99': 500,\n",
    "    'restart_count': 1,\n",
    "    'disk_usage': 60\n",
    "}\n",
    "\n",
    "matches = rule_engine.evaluate(test_metrics)\n",
    "print(f\"Matched {len(matches)} rules:\")\n",
    "for match in matches:\n",
    "    print(f\"  - {match.rule_name}: {match.action} (severity: {match.severity.value})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. AI Decision Integration\n",
    "\n",
    "Import components from the AI decision notebook or recreate minimal versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIDecisionAdapter:\n",
    "    \"\"\"\n",
    "    Adapter for AI decision making.\n",
    "    \n",
    "    Provides a simplified interface to ensemble inference\n",
    "    for use in hybrid workflows.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, models_dir: Path, confidence_threshold: float = 0.75):\n",
    "        self.models_dir = models_dir\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.ensemble_config = self._load_config()\n",
    "        self.feature_names = self.ensemble_config.get('feature_names', [\n",
    "            'cpu_usage', 'memory_percent', 'error_ratio', 'latency_p99',\n",
    "            'restart_count', 'request_rate', 'network_rx', 'network_tx'\n",
    "        ])\n",
    "    \n",
    "    def _load_config(self) -> Dict:\n",
    "        \"\"\"Load ensemble configuration.\"\"\"\n",
    "        config_file = self.models_dir / 'ensemble_config.pkl'\n",
    "        if config_file.exists():\n",
    "            try:\n",
    "                with open(config_file, 'rb') as f:\n",
    "                    return pickle.load(f)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Could not load ensemble config: {e}\")\n",
    "        return {\n",
    "            'methods': ['isolation_forest', 'random_forest'],\n",
    "            'weights': [0.5, 0.5],\n",
    "            'threshold': 0.5\n",
    "        }\n",
    "    \n",
    "    def predict(self, metrics: Dict[str, float]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get AI prediction for metrics.\n",
    "        \n",
    "        Args:\n",
    "            metrics: Current metric values\n",
    "        \n",
    "        Returns:\n",
    "            Prediction with confidence and recommended action\n",
    "        \"\"\"\n",
    "        # Simulate ensemble prediction\n",
    "        # In production, this would call actual trained models\n",
    "        \n",
    "        # Calculate anomaly score based on metric deviations\n",
    "        anomaly_signals = []\n",
    "        \n",
    "        if metrics.get('cpu_usage', 0) > 70:\n",
    "            anomaly_signals.append(min(metrics['cpu_usage'] / 100, 1.0))\n",
    "        if metrics.get('memory_percent', 0) > 80:\n",
    "            anomaly_signals.append(min(metrics['memory_percent'] / 100, 1.0))\n",
    "        if metrics.get('error_ratio', 0) > 0.05:\n",
    "            anomaly_signals.append(min(metrics['error_ratio'] * 5, 1.0))\n",
    "        if metrics.get('latency_p99', 0) > 500:\n",
    "            anomaly_signals.append(min(metrics['latency_p99'] / 2000, 1.0))\n",
    "        if metrics.get('restart_count', 0) > 2:\n",
    "            anomaly_signals.append(min(metrics['restart_count'] / 5, 1.0))\n",
    "        \n",
    "        if anomaly_signals:\n",
    "            anomaly_score = np.mean(anomaly_signals)\n",
    "            # Add some randomness to simulate model uncertainty\n",
    "            noise = np.random.uniform(-0.1, 0.1)\n",
    "            anomaly_score = np.clip(anomaly_score + noise, 0, 1)\n",
    "        else:\n",
    "            anomaly_score = np.random.uniform(0.1, 0.3)\n",
    "        \n",
    "        # Determine confidence (higher when score is far from 0.5)\n",
    "        confidence = 0.5 + abs(anomaly_score - 0.5)\n",
    "        confidence = np.clip(confidence + np.random.uniform(-0.05, 0.15), 0.5, 0.99)\n",
    "        \n",
    "        is_anomaly = anomaly_score > 0.5\n",
    "        \n",
    "        # Classify anomaly type\n",
    "        anomaly_type = self._classify_anomaly(metrics) if is_anomaly else 'normal'\n",
    "        \n",
    "        # Recommend action\n",
    "        action = self._recommend_action(anomaly_type, confidence)\n",
    "        \n",
    "        return {\n",
    "            'is_anomaly': is_anomaly,\n",
    "            'anomaly_score': anomaly_score,\n",
    "            'confidence': confidence,\n",
    "            'anomaly_type': anomaly_type,\n",
    "            'recommended_action': action,\n",
    "            'model_agreement': np.random.uniform(0.7, 1.0),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "    \n",
    "    def _classify_anomaly(self, metrics: Dict[str, float]) -> str:\n",
    "        \"\"\"Classify the type of anomaly.\"\"\"\n",
    "        scores = {\n",
    "            'cpu_anomaly': metrics.get('cpu_usage', 0) / 100,\n",
    "            'memory_anomaly': metrics.get('memory_percent', 0) / 100,\n",
    "            'error_anomaly': min(metrics.get('error_ratio', 0) * 10, 1.0),\n",
    "            'latency_anomaly': min(metrics.get('latency_p99', 0) / 2000, 1.0),\n",
    "            'stability_anomaly': min(metrics.get('restart_count', 0) / 5, 1.0)\n",
    "        }\n",
    "        return max(scores, key=scores.get)\n",
    "    \n",
    "    def _recommend_action(self, anomaly_type: str, confidence: float) -> str:\n",
    "        \"\"\"Recommend action based on anomaly type.\"\"\"\n",
    "        actions = {\n",
    "            'cpu_anomaly': 'scale_horizontal',\n",
    "            'memory_anomaly': 'restart_pod',\n",
    "            'error_anomaly': 'restart_pod',\n",
    "            'latency_anomaly': 'scale_horizontal',\n",
    "            'stability_anomaly': 'diagnose_and_restart',\n",
    "            'normal': 'monitor_only'\n",
    "        }\n",
    "        return actions.get(anomaly_type, 'monitor_only')\n",
    "\n",
    "\n",
    "# Initialize AI adapter\n",
    "ai_adapter = AIDecisionAdapter(MODELS_DIR, AI_CONFIDENCE_THRESHOLD)\n",
    "\n",
    "# Test AI prediction\n",
    "ai_prediction = ai_adapter.predict(test_metrics)\n",
    "print(\"AI Prediction:\")\n",
    "print(json.dumps(ai_prediction, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Intelligent Decision Router\n",
    "\n",
    "Routes decisions between rule-based and AI approaches based on context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoutingStrategy(Enum):\n",
    "    \"\"\"Decision routing strategies.\"\"\"\n",
    "    RULE_BASED = 'rule_based'\n",
    "    AI_DRIVEN = 'ai_driven'\n",
    "    HYBRID = 'hybrid'\n",
    "    CONSERVATIVE = 'conservative'  # Requires agreement\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RoutingDecision:\n",
    "    \"\"\"Routing decision output.\"\"\"\n",
    "    strategy: RoutingStrategy\n",
    "    reasoning: List[str]\n",
    "    rule_weight: float\n",
    "    ai_weight: float\n",
    "    confidence: float\n",
    "    metadata: Dict = field(default_factory=dict)\n",
    "\n",
    "\n",
    "class DecisionRouter:\n",
    "    \"\"\"\n",
    "    Intelligent decision router.\n",
    "    \n",
    "    Determines whether to use rule-based, AI-driven, or hybrid\n",
    "    approach based on context and historical performance.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Default weights\n",
    "    DEFAULT_RULE_WEIGHT = 0.6\n",
    "    DEFAULT_AI_WEIGHT = 0.4\n",
    "    \n",
    "    # Anomaly types where rules are preferred\n",
    "    RULE_PREFERRED_TYPES = {\n",
    "        'high_cpu', 'high_memory', 'crash_loop', 'oom_risk',\n",
    "        'critical_cpu', 'critical_error_rate'\n",
    "    }\n",
    "    \n",
    "    # Anomaly types where AI is preferred\n",
    "    AI_PREFERRED_TYPES = {\n",
    "        'unknown', 'complex_pattern', 'multi_factor', 'gradual_degradation'\n",
    "    }\n",
    "    \n",
    "    def __init__(self, feedback_dir: Path):\n",
    "        self.feedback_dir = feedback_dir\n",
    "        self._performance_history = self._load_performance_history()\n",
    "        self._adaptive_weights = {\n",
    "            'rule': self.DEFAULT_RULE_WEIGHT,\n",
    "            'ai': self.DEFAULT_AI_WEIGHT\n",
    "        }\n",
    "    \n",
    "    def _load_performance_history(self) -> Dict:\n",
    "        \"\"\"Load historical performance data.\"\"\"\n",
    "        history_file = self.feedback_dir / 'routing_performance.json'\n",
    "        if history_file.exists():\n",
    "            try:\n",
    "                with open(history_file, 'r') as f:\n",
    "                    return json.load(f)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Could not load performance history: {e}\")\n",
    "        return {\n",
    "            'rule_based': {'successes': 0, 'failures': 0},\n",
    "            'ai_driven': {'successes': 0, 'failures': 0},\n",
    "            'hybrid': {'successes': 0, 'failures': 0}\n",
    "        }\n",
    "    \n",
    "    def _save_performance_history(self):\n",
    "        \"\"\"Persist performance history.\"\"\"\n",
    "        history_file = self.feedback_dir / 'routing_performance.json'\n",
    "        with open(history_file, 'w') as f:\n",
    "            json.dump(self._performance_history, f, indent=2)\n",
    "    \n",
    "    def _get_success_rate(self, strategy: str) -> float:\n",
    "        \"\"\"Calculate success rate for a strategy.\"\"\"\n",
    "        data = self._performance_history.get(strategy, {})\n",
    "        total = data.get('successes', 0) + data.get('failures', 0)\n",
    "        if total == 0:\n",
    "            return 0.5  # No data, assume neutral\n",
    "        return data.get('successes', 0) / total\n",
    "    \n",
    "    def record_outcome(self, strategy: str, success: bool):\n",
    "        \"\"\"Record outcome for adaptive learning.\"\"\"\n",
    "        if strategy not in self._performance_history:\n",
    "            self._performance_history[strategy] = {'successes': 0, 'failures': 0}\n",
    "        \n",
    "        if success:\n",
    "            self._performance_history[strategy]['successes'] += 1\n",
    "        else:\n",
    "            self._performance_history[strategy]['failures'] += 1\n",
    "        \n",
    "        self._save_performance_history()\n",
    "        self._update_adaptive_weights()\n",
    "    \n",
    "    def _update_adaptive_weights(self):\n",
    "        \"\"\"Update weights based on historical performance.\"\"\"\n",
    "        rule_rate = self._get_success_rate('rule_based')\n",
    "        ai_rate = self._get_success_rate('ai_driven')\n",
    "        \n",
    "        # Adjust weights based on relative performance\n",
    "        total = rule_rate + ai_rate\n",
    "        if total > 0:\n",
    "            self._adaptive_weights['rule'] = rule_rate / total\n",
    "            self._adaptive_weights['ai'] = ai_rate / total\n",
    "    \n",
    "    def route(self, \n",
    "              rule_match: Optional[RuleMatch],\n",
    "              ai_prediction: Dict,\n",
    "              severity: Optional[Severity] = None) -> RoutingDecision:\n",
    "        \"\"\"\n",
    "        Route decision to appropriate strategy.\n",
    "        \n",
    "        Args:\n",
    "            rule_match: Best matching rule (or None)\n",
    "            ai_prediction: AI model prediction\n",
    "            severity: Override severity level\n",
    "        \n",
    "        Returns:\n",
    "            RoutingDecision with strategy and weights\n",
    "        \"\"\"\n",
    "        reasoning = []\n",
    "        \n",
    "        # Extract key information\n",
    "        has_rule_match = rule_match is not None and rule_match.confidence > 0\n",
    "        ai_confidence = ai_prediction.get('confidence', 0)\n",
    "        ai_is_anomaly = ai_prediction.get('is_anomaly', False)\n",
    "        anomaly_type = ai_prediction.get('anomaly_type', 'unknown')\n",
    "        \n",
    "        # Determine severity\n",
    "        if severity is None:\n",
    "            if has_rule_match:\n",
    "                severity = rule_match.severity\n",
    "            elif ai_confidence > 0.9:\n",
    "                severity = Severity.HIGH\n",
    "            else:\n",
    "                severity = Severity.MEDIUM\n",
    "        \n",
    "        # Decision logic\n",
    "        \n",
    "        # Case 1: Critical severity - always use rules if available\n",
    "        if severity == Severity.CRITICAL:\n",
    "            if has_rule_match:\n",
    "                reasoning.append(\"Critical severity: using rule-based for reliability\")\n",
    "                return RoutingDecision(\n",
    "                    strategy=RoutingStrategy.RULE_BASED,\n",
    "                    reasoning=reasoning,\n",
    "                    rule_weight=1.0,\n",
    "                    ai_weight=0.0,\n",
    "                    confidence=1.0,\n",
    "                    metadata={'severity': severity.value}\n",
    "                )\n",
    "            else:\n",
    "                reasoning.append(\"Critical severity but no rule match: conservative approach\")\n",
    "                return RoutingDecision(\n",
    "                    strategy=RoutingStrategy.CONSERVATIVE,\n",
    "                    reasoning=reasoning,\n",
    "                    rule_weight=0.5,\n",
    "                    ai_weight=0.5,\n",
    "                    confidence=ai_confidence,\n",
    "                    metadata={'requires_approval': True}\n",
    "                )\n",
    "        \n",
    "        # Case 2: Rule match with known anomaly type\n",
    "        if has_rule_match and rule_match.rule_id.replace('rule_', '') in self.RULE_PREFERRED_TYPES:\n",
    "            reasoning.append(f\"Known anomaly type '{rule_match.rule_name}': preferring rules\")\n",
    "            return RoutingDecision(\n",
    "                strategy=RoutingStrategy.RULE_BASED,\n",
    "                reasoning=reasoning,\n",
    "                rule_weight=0.8,\n",
    "                ai_weight=0.2,\n",
    "                confidence=rule_match.confidence,\n",
    "                metadata={'rule_id': rule_match.rule_id}\n",
    "            )\n",
    "        \n",
    "        # Case 3: High AI confidence with no rule match\n",
    "        if not has_rule_match and ai_confidence >= HIGH_CONFIDENCE_THRESHOLD:\n",
    "            reasoning.append(f\"No rule match, high AI confidence ({ai_confidence:.1%}): using AI\")\n",
    "            return RoutingDecision(\n",
    "                strategy=RoutingStrategy.AI_DRIVEN,\n",
    "                reasoning=reasoning,\n",
    "                rule_weight=0.2,\n",
    "                ai_weight=0.8,\n",
    "                confidence=ai_confidence,\n",
    "                metadata={'ai_anomaly_type': anomaly_type}\n",
    "            )\n",
    "        \n",
    "        # Case 4: Both match - use hybrid with adaptive weights\n",
    "        if has_rule_match and ai_is_anomaly:\n",
    "            reasoning.append(\"Both rule and AI indicate anomaly: using hybrid approach\")\n",
    "            reasoning.append(f\"Adaptive weights - Rule: {self._adaptive_weights['rule']:.1%}, AI: {self._adaptive_weights['ai']:.1%}\")\n",
    "            return RoutingDecision(\n",
    "                strategy=RoutingStrategy.HYBRID,\n",
    "                reasoning=reasoning,\n",
    "                rule_weight=self._adaptive_weights['rule'],\n",
    "                ai_weight=self._adaptive_weights['ai'],\n",
    "                confidence=(rule_match.confidence + ai_confidence) / 2,\n",
    "                metadata={'agreement': True}\n",
    "            )\n",
    "        \n",
    "        # Case 5: Disagreement - be conservative\n",
    "        if has_rule_match != ai_is_anomaly:\n",
    "            reasoning.append(\"Rule and AI disagree: conservative approach with monitoring\")\n",
    "            return RoutingDecision(\n",
    "                strategy=RoutingStrategy.CONSERVATIVE,\n",
    "                reasoning=reasoning,\n",
    "                rule_weight=0.5,\n",
    "                ai_weight=0.5,\n",
    "                confidence=max(rule_match.confidence if has_rule_match else 0, ai_confidence) * 0.7,\n",
    "                metadata={'disagreement': True}\n",
    "            )\n",
    "        \n",
    "        # Case 6: Neither triggered - monitor only\n",
    "        reasoning.append(\"No anomaly detected by either system\")\n",
    "        return RoutingDecision(\n",
    "            strategy=RoutingStrategy.RULE_BASED,  # Default to rules for monitoring\n",
    "            reasoning=reasoning,\n",
    "            rule_weight=0.5,\n",
    "            ai_weight=0.5,\n",
    "            confidence=1.0 - max(ai_confidence, 0.5),\n",
    "            metadata={'action': 'monitor_only'}\n",
    "        )\n",
    "\n",
    "\n",
    "# Initialize router\n",
    "router = DecisionRouter(FEEDBACK_DIR)\n",
    "\n",
    "# Test routing\n",
    "rule_match = rule_engine.get_best_action(test_metrics)\n",
    "routing = router.route(rule_match, ai_prediction)\n",
    "\n",
    "print(f\"\\nRouting Decision:\")\n",
    "print(f\"  Strategy: {routing.strategy.value}\")\n",
    "print(f\"  Rule Weight: {routing.rule_weight:.1%}\")\n",
    "print(f\"  AI Weight: {routing.ai_weight:.1%}\")\n",
    "print(f\"  Confidence: {routing.confidence:.1%}\")\n",
    "print(f\"  Reasoning:\")\n",
    "for reason in routing.reasoning:\n",
    "    print(f\"    - {reason}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hybrid Decision Maker\n",
    "\n",
    "Combines rule-based and AI decisions with weighted voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class HybridDecision:\n",
    "    \"\"\"Final hybrid decision.\"\"\"\n",
    "    decision_id: str\n",
    "    timestamp: datetime\n",
    "    strategy_used: RoutingStrategy\n",
    "    final_action: str\n",
    "    confidence: float\n",
    "    should_execute: bool\n",
    "    requires_approval: bool\n",
    "    rule_contribution: Optional[Dict]\n",
    "    ai_contribution: Optional[Dict]\n",
    "    reasoning: List[str]\n",
    "    metadata: Dict = field(default_factory=dict)\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        d = asdict(self)\n",
    "        d['timestamp'] = self.timestamp.isoformat()\n",
    "        d['strategy_used'] = self.strategy_used.value\n",
    "        return d\n",
    "\n",
    "\n",
    "class HybridDecisionMaker:\n",
    "    \"\"\"\n",
    "    Makes final decisions by combining rule-based and AI approaches.\n",
    "    \"\"\"\n",
    "    \n",
    "    ACTION_PRIORITY = {\n",
    "        'emergency_scale': 10,\n",
    "        'rollback_deployment': 9,\n",
    "        'increase_memory_limit': 8,\n",
    "        'restart_pod': 7,\n",
    "        'diagnose_and_restart': 6,\n",
    "        'scale_horizontal': 5,\n",
    "        'cleanup_disk': 4,\n",
    "        'notify_operator': 3,\n",
    "        'monitor_only': 1\n",
    "    }\n",
    "    \n",
    "    def __init__(self, \n",
    "                 rule_engine: RuleEngine,\n",
    "                 ai_adapter: AIDecisionAdapter,\n",
    "                 router: DecisionRouter,\n",
    "                 execution_threshold: float = 0.6):\n",
    "        self.rule_engine = rule_engine\n",
    "        self.ai_adapter = ai_adapter\n",
    "        self.router = router\n",
    "        self.execution_threshold = execution_threshold\n",
    "        self._decision_history = []\n",
    "    \n",
    "    def _generate_decision_id(self) -> str:\n",
    "        \"\"\"Generate unique decision ID.\"\"\"\n",
    "        content = f\"{datetime.now().timestamp()}_{np.random.random()}\"\n",
    "        return hashlib.sha256(content.encode()).hexdigest()[:12]\n",
    "    \n",
    "    def _select_action(self,\n",
    "                       rule_action: Optional[str],\n",
    "                       ai_action: str,\n",
    "                       rule_weight: float,\n",
    "                       ai_weight: float) -> str:\n",
    "        \"\"\"Select final action based on weighted priority.\"\"\"\n",
    "        if rule_action is None:\n",
    "            return ai_action\n",
    "        \n",
    "        rule_priority = self.ACTION_PRIORITY.get(rule_action, 0) * rule_weight\n",
    "        ai_priority = self.ACTION_PRIORITY.get(ai_action, 0) * ai_weight\n",
    "        \n",
    "        if rule_priority >= ai_priority:\n",
    "            return rule_action\n",
    "        return ai_action\n",
    "    \n",
    "    def decide(self, metrics: Dict[str, float]) -> HybridDecision:\n",
    "        \"\"\"\n",
    "        Make a hybrid decision based on metrics.\n",
    "        \n",
    "        Args:\n",
    "            metrics: Current metric values\n",
    "        \n",
    "        Returns:\n",
    "            HybridDecision with final action\n",
    "        \"\"\"\n",
    "        reasoning = []\n",
    "        \n",
    "        # Get rule-based decision\n",
    "        rule_match = self.rule_engine.get_best_action(metrics)\n",
    "        if rule_match:\n",
    "            reasoning.append(f\"Rule '{rule_match.rule_name}' matched: {rule_match.action}\")\n",
    "        else:\n",
    "            reasoning.append(\"No rule matched current metrics\")\n",
    "        \n",
    "        # Get AI decision\n",
    "        ai_prediction = self.ai_adapter.predict(metrics)\n",
    "        if ai_prediction['is_anomaly']:\n",
    "            reasoning.append(f\"AI detected anomaly ({ai_prediction['anomaly_type']}): {ai_prediction['recommended_action']}\")\n",
    "        else:\n",
    "            reasoning.append(f\"AI: no anomaly detected (confidence: {ai_prediction['confidence']:.1%})\")\n",
    "        \n",
    "        # Get routing decision\n",
    "        routing = self.router.route(rule_match, ai_prediction)\n",
    "        reasoning.extend(routing.reasoning)\n",
    "        \n",
    "        # Determine final action based on strategy\n",
    "        if routing.strategy == RoutingStrategy.RULE_BASED:\n",
    "            final_action = rule_match.action if rule_match else 'monitor_only'\n",
    "            confidence = rule_match.confidence if rule_match else 0.5\n",
    "        elif routing.strategy == RoutingStrategy.AI_DRIVEN:\n",
    "            final_action = ai_prediction['recommended_action']\n",
    "            confidence = ai_prediction['confidence']\n",
    "        elif routing.strategy == RoutingStrategy.HYBRID:\n",
    "            final_action = self._select_action(\n",
    "                rule_match.action if rule_match else None,\n",
    "                ai_prediction['recommended_action'],\n",
    "                routing.rule_weight,\n",
    "                routing.ai_weight\n",
    "            )\n",
    "            # Hybrid confidence is weighted average\n",
    "            rule_conf = rule_match.confidence if rule_match else 0\n",
    "            confidence = (rule_conf * routing.rule_weight + \n",
    "                         ai_prediction['confidence'] * routing.ai_weight)\n",
    "        else:  # CONSERVATIVE\n",
    "            final_action = 'monitor_only' if not rule_match else rule_match.action\n",
    "            confidence = routing.confidence * 0.8  # Reduce confidence for conservative\n",
    "        \n",
    "        # Determine if we should execute\n",
    "        should_execute = (\n",
    "            final_action != 'monitor_only' and\n",
    "            confidence >= self.execution_threshold and\n",
    "            routing.strategy != RoutingStrategy.CONSERVATIVE\n",
    "        )\n",
    "        \n",
    "        requires_approval = (\n",
    "            routing.strategy == RoutingStrategy.CONSERVATIVE or\n",
    "            (rule_match and rule_match.metadata.get('requires_approval', False)) or\n",
    "            final_action in ['rollback_deployment', 'emergency_scale']\n",
    "        )\n",
    "        \n",
    "        decision = HybridDecision(\n",
    "            decision_id=self._generate_decision_id(),\n",
    "            timestamp=datetime.now(),\n",
    "            strategy_used=routing.strategy,\n",
    "            final_action=final_action,\n",
    "            confidence=confidence,\n",
    "            should_execute=should_execute,\n",
    "            requires_approval=requires_approval,\n",
    "            rule_contribution={\n",
    "                'matched': rule_match is not None,\n",
    "                'action': rule_match.action if rule_match else None,\n",
    "                'confidence': rule_match.confidence if rule_match else 0,\n",
    "                'weight': routing.rule_weight\n",
    "            },\n",
    "            ai_contribution={\n",
    "                'is_anomaly': ai_prediction['is_anomaly'],\n",
    "                'action': ai_prediction['recommended_action'],\n",
    "                'confidence': ai_prediction['confidence'],\n",
    "                'weight': routing.ai_weight\n",
    "            },\n",
    "            reasoning=reasoning,\n",
    "            metadata=routing.metadata\n",
    "        )\n",
    "        \n",
    "        self._decision_history.append(decision.to_dict())\n",
    "        \n",
    "        logger.info(f\"Hybrid decision: {final_action} (strategy: {routing.strategy.value}, \"\n",
    "                   f\"confidence: {confidence:.1%}, execute: {should_execute})\")\n",
    "        \n",
    "        return decision\n",
    "\n",
    "\n",
    "# Initialize hybrid decision maker\n",
    "hybrid_maker = HybridDecisionMaker(\n",
    "    rule_engine=rule_engine,\n",
    "    ai_adapter=ai_adapter,\n",
    "    router=router,\n",
    "    execution_threshold=0.6\n",
    ")\n",
    "\n",
    "# Test hybrid decision\n",
    "decision = hybrid_maker.decide(test_metrics)\n",
    "print(\"\\nHybrid Decision:\")\n",
    "print(json.dumps(decision.to_dict(), indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fallback Chain Executor\n",
    "\n",
    "Execute remediation with fallback strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ExecutionResult:\n",
    "    \"\"\"Result of remediation execution.\"\"\"\n",
    "    decision_id: str\n",
    "    executed: bool\n",
    "    action_taken: str\n",
    "    success: bool\n",
    "    duration_seconds: float\n",
    "    fallback_used: bool\n",
    "    fallback_action: Optional[str]\n",
    "    error_message: Optional[str]\n",
    "    timestamp: datetime\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        d = asdict(self)\n",
    "        d['timestamp'] = self.timestamp.isoformat()\n",
    "        return d\n",
    "\n",
    "\n",
    "class FallbackExecutor:\n",
    "    \"\"\"\n",
    "    Executes remediation with fallback chains.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fallback chains for each action\n",
    "    FALLBACK_CHAINS = {\n",
    "        'scale_horizontal': ['scale_horizontal', 'restart_pod', 'notify_operator'],\n",
    "        'restart_pod': ['restart_pod', 'delete_and_recreate', 'notify_operator'],\n",
    "        'rollback_deployment': ['rollback_deployment', 'restart_pod', 'notify_operator'],\n",
    "        'emergency_scale': ['emergency_scale', 'scale_horizontal', 'restart_pod'],\n",
    "        'increase_memory_limit': ['increase_memory_limit', 'restart_pod', 'scale_horizontal'],\n",
    "        'diagnose_and_restart': ['diagnose_and_restart', 'restart_pod', 'notify_operator'],\n",
    "        'cleanup_disk': ['cleanup_disk', 'restart_pod', 'notify_operator'],\n",
    "        'notify_operator': ['notify_operator'],\n",
    "        'monitor_only': ['monitor_only']\n",
    "    }\n",
    "    \n",
    "    def __init__(self, namespace: str, simulate: bool = True):\n",
    "        self.namespace = namespace\n",
    "        self.simulate = simulate\n",
    "        self._execution_log = []\n",
    "    \n",
    "    def _execute_action(self, action: str) -> Tuple[bool, Optional[str]]:\n",
    "        \"\"\"\n",
    "        Execute a single action.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (success, error_message)\n",
    "        \"\"\"\n",
    "        if self.simulate:\n",
    "            # Simulate execution with realistic success rates\n",
    "            success_rates = {\n",
    "                'scale_horizontal': 0.95,\n",
    "                'restart_pod': 0.90,\n",
    "                'rollback_deployment': 0.85,\n",
    "                'emergency_scale': 0.90,\n",
    "                'increase_memory_limit': 0.80,\n",
    "                'diagnose_and_restart': 0.85,\n",
    "                'cleanup_disk': 0.90,\n",
    "                'delete_and_recreate': 0.80,\n",
    "                'notify_operator': 1.0,\n",
    "                'monitor_only': 1.0\n",
    "            }\n",
    "            success = np.random.random() < success_rates.get(action, 0.8)\n",
    "            error = None if success else f\"Simulated failure for {action}\"\n",
    "            return success, error\n",
    "        else:\n",
    "            # Real execution would go here\n",
    "            # Example: kubectl scale, kubectl rollout restart, etc.\n",
    "            logger.warning(f\"Real execution not implemented for {action}\")\n",
    "            return False, \"Real execution not implemented\"\n",
    "    \n",
    "    def execute(self, decision: HybridDecision) -> ExecutionResult:\n",
    "        \"\"\"\n",
    "        Execute remediation with fallback chain.\n",
    "        \n",
    "        Args:\n",
    "            decision: Hybrid decision to execute\n",
    "        \n",
    "        Returns:\n",
    "            ExecutionResult with outcome\n",
    "        \"\"\"\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        if not decision.should_execute:\n",
    "            return ExecutionResult(\n",
    "                decision_id=decision.decision_id,\n",
    "                executed=False,\n",
    "                action_taken='none',\n",
    "                success=True,\n",
    "                duration_seconds=0,\n",
    "                fallback_used=False,\n",
    "                fallback_action=None,\n",
    "                error_message='Execution not required',\n",
    "                timestamp=datetime.now()\n",
    "            )\n",
    "        \n",
    "        if decision.requires_approval:\n",
    "            logger.info(f\"Action {decision.final_action} requires approval - skipping\")\n",
    "            return ExecutionResult(\n",
    "                decision_id=decision.decision_id,\n",
    "                executed=False,\n",
    "                action_taken='pending_approval',\n",
    "                success=False,\n",
    "                duration_seconds=0,\n",
    "                fallback_used=False,\n",
    "                fallback_action=None,\n",
    "                error_message='Awaiting operator approval',\n",
    "                timestamp=datetime.now()\n",
    "            )\n",
    "        \n",
    "        # Get fallback chain\n",
    "        chain = self.FALLBACK_CHAINS.get(decision.final_action, [decision.final_action, 'notify_operator'])\n",
    "        \n",
    "        action_taken = None\n",
    "        fallback_used = False\n",
    "        success = False\n",
    "        error_message = None\n",
    "        \n",
    "        for i, action in enumerate(chain):\n",
    "            logger.info(f\"Attempting action: {action} (attempt {i+1}/{len(chain)})\")\n",
    "            \n",
    "            success, error = self._execute_action(action)\n",
    "            action_taken = action\n",
    "            \n",
    "            if success:\n",
    "                if i > 0:\n",
    "                    fallback_used = True\n",
    "                break\n",
    "            else:\n",
    "                error_message = error\n",
    "                logger.warning(f\"Action {action} failed: {error}\")\n",
    "        \n",
    "        duration = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        result = ExecutionResult(\n",
    "            decision_id=decision.decision_id,\n",
    "            executed=True,\n",
    "            action_taken=action_taken,\n",
    "            success=success,\n",
    "            duration_seconds=duration + np.random.uniform(5, 30),  # Add simulated work time\n",
    "            fallback_used=fallback_used,\n",
    "            fallback_action=action_taken if fallback_used else None,\n",
    "            error_message=error_message if not success else None,\n",
    "            timestamp=datetime.now()\n",
    "        )\n",
    "        \n",
    "        self._execution_log.append(result.to_dict())\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "# Initialize executor\n",
    "executor = FallbackExecutor(NAMESPACE, simulate=True)\n",
    "\n",
    "# Test execution\n",
    "if decision.should_execute:\n",
    "    result = executor.execute(decision)\n",
    "    print(\"\\nExecution Result:\")\n",
    "    print(json.dumps(result.to_dict(), indent=2, default=str))\n",
    "else:\n",
    "    print(\"\\nDecision does not require execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Complete Hybrid Workflow\n",
    "\n",
    "Run the full workflow with metrics, decision, and execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hybrid_workflow(metrics: Dict[str, float], \n",
    "                        record_outcome: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Run complete hybrid healing workflow.\n",
    "    \n",
    "    Args:\n",
    "        metrics: Current metric values\n",
    "        record_outcome: Whether to record outcome for learning\n",
    "    \n",
    "    Returns:\n",
    "        Workflow result with all stages\n",
    "    \"\"\"\n",
    "    workflow_start = datetime.now()\n",
    "    workflow_id = hashlib.sha256(str(workflow_start).encode()).hexdigest()[:12]\n",
    "    \n",
    "    logger.info(f\"Starting hybrid workflow {workflow_id}\")\n",
    "    \n",
    "    # Stage 1: Make hybrid decision\n",
    "    decision = hybrid_maker.decide(metrics)\n",
    "    \n",
    "    # Stage 2: Execute with fallback\n",
    "    execution = executor.execute(decision)\n",
    "    \n",
    "    # Stage 3: Record outcome for adaptive learning\n",
    "    if record_outcome and execution.executed:\n",
    "        router.record_outcome(\n",
    "            strategy=decision.strategy_used.value,\n",
    "            success=execution.success\n",
    "        )\n",
    "    \n",
    "    workflow_duration = (datetime.now() - workflow_start).total_seconds()\n",
    "    \n",
    "    return {\n",
    "        'workflow_id': workflow_id,\n",
    "        'duration_seconds': workflow_duration,\n",
    "        'decision': decision.to_dict(),\n",
    "        'execution': execution.to_dict(),\n",
    "        'summary': {\n",
    "            'strategy': decision.strategy_used.value,\n",
    "            'action': decision.final_action,\n",
    "            'confidence': f\"{decision.confidence:.1%}\",\n",
    "            'executed': execution.executed,\n",
    "            'success': execution.success,\n",
    "            'fallback_used': execution.fallback_used\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "# Run single workflow\n",
    "result = run_hybrid_workflow(test_metrics)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WORKFLOW SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(json.dumps(result['summary'], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batch Simulation\n",
    "\n",
    "Run multiple workflows to gather performance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_metrics() -> Dict[str, float]:\n",
    "    \"\"\"Generate random test metrics with realistic distributions.\"\"\"\n",
    "    return {\n",
    "        'cpu_usage': np.random.beta(2, 5) * 100,  # Usually low, sometimes high\n",
    "        'memory_percent': np.random.beta(3, 2) * 100,  # Usually higher\n",
    "        'error_ratio': np.random.exponential(0.03),  # Mostly low, occasional spikes\n",
    "        'latency_p99': np.random.lognormal(6, 0.8),  # Log-normal latency\n",
    "        'restart_count': np.random.poisson(0.5),  # Usually 0, sometimes more\n",
    "        'request_rate': np.random.exponential(100),\n",
    "        'network_rx': np.random.exponential(1e7),\n",
    "        'network_tx': np.random.exponential(5e6),\n",
    "        'disk_usage': np.random.beta(2, 3) * 100\n",
    "    }\n",
    "\n",
    "\n",
    "# Run batch simulation\n",
    "NUM_WORKFLOWS = 30\n",
    "batch_results = []\n",
    "\n",
    "print(f\"Running {NUM_WORKFLOWS} hybrid workflows...\\n\")\n",
    "print(f\"{'#':>3} {'Strategy':<12} {'Action':<20} {'Conf':>6} {'Exec':>5} {'Success':>7} {'Fallback':>8}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for i in range(NUM_WORKFLOWS):\n",
    "    metrics = generate_test_metrics()\n",
    "    result = run_hybrid_workflow(metrics, record_outcome=True)\n",
    "    batch_results.append(result)\n",
    "    \n",
    "    s = result['summary']\n",
    "    print(f\"{i+1:3d} {s['strategy']:<12} {s['action']:<20} {s['confidence']:>6} \"\n",
    "          f\"{'Yes' if s['executed'] else 'No':>5} {'✅' if s['success'] else '❌':>7} \"\n",
    "          f\"{'Yes' if s['fallback_used'] else 'No':>8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results\n",
    "df = pd.DataFrame([r['summary'] for r in batch_results])\n",
    "df['confidence_num'] = df['confidence'].str.rstrip('%').astype(float) / 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Overall metrics\n",
    "print(\"\\n📊 Overall Metrics:\")\n",
    "print(f\"  Total workflows: {len(df)}\")\n",
    "print(f\"  Execution rate: {df['executed'].mean():.1%}\")\n",
    "print(f\"  Success rate (of executed): {df[df['executed']]['success'].mean():.1%}\")\n",
    "print(f\"  Fallback rate: {df['fallback_used'].mean():.1%}\")\n",
    "print(f\"  Average confidence: {df['confidence_num'].mean():.1%}\")\n",
    "\n",
    "# By strategy\n",
    "print(\"\\n📈 By Strategy:\")\n",
    "strategy_stats = df.groupby('strategy').agg({\n",
    "    'executed': ['count', 'mean'],\n",
    "    'success': 'mean',\n",
    "    'confidence_num': 'mean'\n",
    "}).round(3)\n",
    "print(strategy_stats.to_string())\n",
    "\n",
    "# By action\n",
    "print(\"\\n🔧 By Action:\")\n",
    "action_counts = df['action'].value_counts()\n",
    "for action, count in action_counts.items():\n",
    "    action_df = df[df['action'] == action]\n",
    "    success_rate = action_df['success'].mean() if len(action_df) > 0 else 0\n",
    "    print(f\"  {action}: {count} ({success_rate:.0%} success)\")\n",
    "\n",
    "# Adaptive weights\n",
    "print(\"\\n⚖️ Adaptive Weights (after learning):\")\n",
    "print(f\"  Rule weight: {router._adaptive_weights['rule']:.1%}\")\n",
    "print(f\"  AI weight: {router._adaptive_weights['ai']:.1%}\")\n",
    "\n",
    "# Performance history\n",
    "print(\"\\n📜 Performance History:\")\n",
    "for strategy, data in router._performance_history.items():\n",
    "    total = data['successes'] + data['failures']\n",
    "    rate = data['successes'] / total if total > 0 else 0\n",
    "    print(f\"  {strategy}: {data['successes']}/{total} ({rate:.0%} success)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save workflow tracking data\n",
    "tracking_df = pd.DataFrame([r['summary'] for r in batch_results])\n",
    "tracking_df['timestamp'] = [r['decision']['timestamp'] for r in batch_results]\n",
    "tracking_df['workflow_id'] = [r['workflow_id'] for r in batch_results]\n",
    "\n",
    "tracking_file = PROCESSED_DIR / 'hybrid_workflow_tracking.parquet'\n",
    "tracking_df.to_parquet(tracking_file)\n",
    "logger.info(f\"Saved tracking data to {tracking_file}\")\n",
    "\n",
    "# Save detailed results\n",
    "detailed_file = PROCESSED_DIR / 'hybrid_workflow_detailed.json'\n",
    "with open(detailed_file, 'w') as f:\n",
    "    json.dump(batch_results, f, indent=2, default=str)\n",
    "logger.info(f\"Saved detailed results to {detailed_file}\")\n",
    "\n",
    "print(f\"\\n✅ Results saved:\")\n",
    "print(f\"  - {tracking_file}\")\n",
    "print(f\"  - {detailed_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate all components\n",
    "print(\"VALIDATION CHECKS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "checks = {\n",
    "    'Rule engine initialized': len(rule_engine.rules) > 0,\n",
    "    'AI adapter working': 'confidence' in ai_prediction,\n",
    "    'Router functioning': routing.strategy is not None,\n",
    "    'Hybrid maker working': decision.decision_id is not None,\n",
    "    'Executor functioning': len(executor._execution_log) > 0,\n",
    "    'Batch simulation complete': len(batch_results) == NUM_WORKFLOWS,\n",
    "    'Tracking file created': tracking_file.exists(),\n",
    "    'Adaptive learning active': sum(router._performance_history['rule_based'].values()) > 0,\n",
    "}\n",
    "\n",
    "all_passed = True\n",
    "for check, passed in checks.items():\n",
    "    status = \"✅\" if passed else \"❌\"\n",
    "    print(f\"{status} {check}\")\n",
    "    all_passed = all_passed and passed\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if all_passed:\n",
    "    print(\"✅ ALL VALIDATIONS PASSED\")\n",
    "else:\n",
    "    print(\"❌ SOME VALIDATIONS FAILED\")\n",
    "\n",
    "print(f\"\\n📋 Hybrid Healing Summary:\")\n",
    "print(f\"  Rules defined: {len(rule_engine.rules)}\")\n",
    "print(f\"  Workflows executed: {len(batch_results)}\")\n",
    "print(f\"  Overall success rate: {df[df['executed']]['success'].mean():.1%}\")\n",
    "print(f\"  Strategies used: {df['strategy'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration Notes\n",
    "\n",
    "### Components\n",
    "\n",
    "1. **RuleEngine** - 10 predefined rules covering:\n",
    "   - CPU (high, critical)\n",
    "   - Memory (high, OOM risk)\n",
    "   - Error rates (high, critical)\n",
    "   - Latency, crash loops, network, disk\n",
    "   - Built-in cooldown and rate limiting\n",
    "\n",
    "2. **AIDecisionAdapter** - Wraps ensemble model inference\n",
    "   - Anomaly classification\n",
    "   - Confidence scoring\n",
    "   - Action recommendation\n",
    "\n",
    "3. **DecisionRouter** - Intelligent routing with:\n",
    "   - Severity-based routing\n",
    "   - Known vs unknown anomaly handling\n",
    "   - Adaptive weights from outcome feedback\n",
    "   - Conservative mode for disagreements\n",
    "\n",
    "4. **HybridDecisionMaker** - Combines both approaches:\n",
    "   - Weighted action selection\n",
    "   - Combined confidence scoring\n",
    "   - Approval requirements\n",
    "\n",
    "5. **FallbackExecutor** - Resilient execution:\n",
    "   - Action-specific fallback chains\n",
    "   - Automatic retry on failure\n",
    "   - Execution logging\n",
    "\n",
    "### Integration with AI-Driven Notebook\n",
    "\n",
    "This notebook builds on `ai-driven-decision-making-enhanced.ipynb`:\n",
    "- Uses similar feature extraction patterns\n",
    "- Compatible outcome tracking format\n",
    "- Shared confidence thresholds\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Connect to live Prometheus metrics\n",
    "2. Implement real Kubernetes actions\n",
    "3. Add more sophisticated rules\n",
    "4. Integrate with MCP coordination engine\n",
    "5. Deploy as part of self-healing platform"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
